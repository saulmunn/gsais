<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Guaranteed Safe AI Summit</title>
    <style>
      :root {
        --primary-color: #2c3e50;
        --secondary-color: #3498db;
        --accent-color: #27ae60;
        --light-color: #ecf0f1;
        --dark-color: #2c3e50;
      }

      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        line-height: 1.6;
        color: var(--dark-color);
        background-color: #f9f9f9;
      }

      header {
        background-color: var(--primary-color);
        color: white;
        text-align: center;
        padding: 2rem 0;
      }

      .logo-container {
        margin-bottom: 1rem;
      }

      .logo-text {
        font-size: 2.5rem;
        font-weight: 700;
        letter-spacing: 1px;
      }

      nav {
        background-color: rgba(255, 255, 255, 0.1);
        padding: 1rem 0;
      }

      nav ul {
        display: flex;
        justify-content: center;
        list-style: none;
      }

      nav ul li {
        margin: 0 1.5rem;
      }

      nav ul li a {
        color: white;
        text-decoration: none;
        font-weight: 500;
        transition: color 0.3s;
      }

      nav ul li a:hover {
        color: var(--secondary-color);
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
      }

      section {
        margin-bottom: 3rem;
      }

      h1,
      h2,
      h3 {
        margin-bottom: 1rem;
        color: var(--primary-color);
      }

      h1 {
        font-size: 2.5rem;
      }

      h2 {
        font-size: 2rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid var(--light-color);
      }

      h3 {
        font-size: 1.5rem;
        color: var(--secondary-color);
      }

      p {
        margin-bottom: 1.5rem;
      }

      .about-image-container {
        max-width: 800px; /* Adjust based on actual text width */
        margin: 0 auto; /* Centers the image */
      }

      .about-image {
        width: 100%; /* Makes it scale to the container */
        height: auto; /* Maintains aspect ratio */
        display: block;
      }

      .btn {
        display: inline-block;
        background-color: var(--accent-color);
        color: white;
        padding: 0.75rem 1.5rem;
        text-decoration: none;
        border-radius: 5px;
        font-weight: 600;
        transition: background-color 0.3s;
      }

      .btn:hover {
        background-color: var(--secondary-color);
      }

      .highlight {
        background-color: var(--light-color);
        border-left: 4px solid var(--accent-color);
        padding: 1.5rem;
        margin-bottom: 1.5rem;
      }

      .organizers {
        display: flex;
        flex-wrap: wrap;
        gap: 2rem;
        margin-top: 1.5rem;
      }

      .organizer {
        flex: 1;
        min-width: 300px;
      }

      .schedule {
        margin-top: 1.5rem;
      }

      .schedule-day {
        margin-bottom: 2rem;
      }

      .schedule-item {
        margin-bottom: 1rem;
        padding-left: 1rem;
        border-left: 3px solid var(--secondary-color);
      }

      footer {
        background-color: var(--primary-color);
        color: white;
        text-align: center;
        padding: 2rem 0;
        margin-top: 2rem;
      }

      footer a {
        color: var(--light-color);
      }

      @media (max-width: 768px) {
        .logo-text {
          font-size: 2rem;
        }

        nav ul {
          flex-direction: column;
          align-items: center;
        }

        nav ul li {
          margin: 0.5rem 0;
        }
      }
    </style>
  </head>
  <body>
    <header>
      <div class="logo-container">
        <div class="logo-text">GSAIS</div>
        <p>Guaranteed Safe AI Summit</p>
      </div>
      <nav>
        <ul>
          <li><a href="#about">About</a></li>
          <li><a href="#gsai">GSAI Research</a></li>
          <li><a href="#organizers">Organizers</a></li>
          <li><a href="#sponsors">Sponsors</a></li>
        </ul>
      </nav>
    </header>

    <main class="container">
      <section id="about">
        <h2>About the March 2025 Summit</h2>
        <p>
          The <strong>Guaranteed Safe AI (GSAI) Summit</strong> was a 2-day
          gathering in San Francisco on March 8-9, 2025.  Leading researchers, funders, 
          and experts of industry gathered to identify bottlenecks and advance the 
          paradigm of <a href="#gsai">guaranteed safe AI</a>.
          The summit set out to advance research, collaboration, and forward
          progress in the field.  The agenda included multiple breakout sessions for structured discussions, unstructured time for collaborations, and presentations from Yoshua Bengio, Stuart Russell, Luke Ong, Max Tegmark, Dawn Song, Steve Omohundro, Clark Barrett, davidad, and Sanjit Seshia.
        </p>
          <div class="about-image-container">
            <img src="gsai-summit-group-crop.jpeg" alt="GSAIS Logo" class="about-image" />
          </div>
        <p>
          Given attendee interest, we are looking into organizing a subsequent event in the fall.
        </p>
      </section>
     
      <section id="gsai">
        <h2>The Guaranteed Safe AI Framework</h2>
        <p>
          Guaranteed Safe AI (GSAI) is an emerging framework that provides quantifiable guarantees of AI safety.  
        </p>

        <p>
          As AI systems become more powerful and autonomous, traditional
          empirical safety assessment methods like red-teaming and evals become increasingly insufficient to mitigate risks from misalignment or misuse.
        </p>
        <p>
          Approaches that follow the GSAI framework aim to provide the level of quantitative safety guarantees we've come to expect from other engineered systems. This is achieved with three core components: an auditable, separable world model, a way to describe what portions of the state space are "safe" and "unsafe," and a verifier (which provides an auditable proof certificate that the output satisfy the safety specification in the world model).
        </p>
        <p>
          For more on GSAI, take a look at the seminal paper
          <a href="https://arxiv.org/abs/2405.06624" target="_blank"
            >Towards Guaranteed Safe AI: A Framework for Ensuring Robust and
            Reliable AI Systems</a
          >.  And if you'd like to join or support this research effort, we also have 
          <a href="https://groups.google.com/g/guaranteed-safe-ai/" target="_blank" 
            >a public email list</a>.  
        </p>
      </section>

      <section id="organizers">
        <h2>Organizers</h2>
        <div class="organizers">
          <div class="organizer">
            <h4>
              <a
                href="https://www.linkedin.com/in/evan-miyazono/"
                target="_blank"
                style="color: var(--secondary-color); text-decoration: none"
                >Evan Miyazono</a
              >
            </h4>
            <p>
              Evan is the founder & CEO of <a href="https://atlascomputing.org/">Atlas Computing</a>, an R&D nonprofit prototyping AI-powered tools to generate formal specifications.
              Evan previously led initiatives at <a href="https://www.protocol.ai/">Protocol Labs</a>, an innovation network driving breakthroughs in computing, to push humanity forward.
            </p>
          </div>
          <div class="organizer">
            <h4>
              <a
                href="https://nora-ammann.replit.app/"
                target="_blank"
                style="color: var(--secondary-color); text-decoration: none"
                >Nora Ammann</a
              >
            </h4>
            <p>
              Nora focuseses on developing quantitative safety guarantees for AI systems at the <a href="https://www.aria.org.uk/programme-safeguarded-ai/" target="_blank">Safeguarded AI programme</a> at the UK's
              Advanced Research and Invention Agency (ARIA). She also
              contributes to research on Flexible Hardware-Enabled Guarantees
              (flexHEG) for AI governance. She previously co-founded and led a research initiative fostering interdisciplinary AI safety research <a href="https://nora-ammann.replit.app/pibbss.ai" target="_blank">(PIBBSS)</a>.
            </p>
          </div>
          <div class="organizer">
            <h4>
              <a
                href="https://www.linkedin.com/in/bgoldhaber/"
                target="_blank"
                style="color: var(--secondary-color); text-decoration: none"
                >Ben Goldhaber</a
              >
            </h4>
            <p>
              Ben is the Projects Lead at the <a href="https://www.flf.org/" target="_blank">Future of Life Foundation</a>. 
              Previously, he was the cofounder & board member of the <a href="https://quantifieduncertainty.org/" target="_blank">Quantified Research Institute</a> and the director of <a href="https://far.ai/" target="_blank">FAR AI</a>, an AI safety research lab that incubates and accelerates research agendas that are too resource-intensive for academia but not yet ready for commercialisation by industry.
            </p>
          </div>
        </div>
      </section>

      <section id="sponsors">
        <h2>Sponsors</h2>
        <p>
          The Guaranteed Safe AI Summit was made possible through the generous
          support of <strong><a href="https://www.beneficialaifoundation.org/" target="_blank">The Beneficial AI Foundation</a></strong>, and generously hosted by <strong><a href="https://www.futurehouse.org/" target="_blank">FutureHouse</a></strong>
        </p>
      </section>
    </main>

    <footer>
      <p>
        For more information, reach out to Evan Miyazono (evan <i>at</i> atlascomputing <i>dot</i> org).
      </p>
      <p style="font-size: 0.7em; color: #a8b5c3">Website built by <a href="https://www.cursor.com/en">Cursor</a>, <a href="https://saulmunn.com">Saul</a>, and Evan.</p>
    </footer>
  </body>
</html>
